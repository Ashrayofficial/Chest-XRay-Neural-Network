# -*- coding: utf-8 -*-
"""NN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ox8wJQILYNh3KqYz7id7GBSLb0gXpLmS
"""

import tensorflow as tf
import os
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import keras
from keras import models
from keras.callbacks import ReduceLROnPlateau
from keras.utils import vis_utils

from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

image_size = 200

def data_loader(data_dir):
    data = list()
    for label in labels:
        path = os.path.join(data_dir, label)
        class_num = labels.index(label)
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)
                resized_arr = cv2.resize(img_arr, (image_size, image_size))
                data.append([resized_arr, class_num])
            except Exception as e:
                print(e)

    return np.array(data)

labels = ['Covid', 'Normal','Viral Pneumonia']

test = data_loader('/content/drive/MyDrive/Covid19-dataset/test')
train = data_loader('/content/drive/MyDrive/Covid19-dataset/train')

len(train)

len(test)

plt.figure(figsize=(12, 12))
plt.imshow(train[25][0])
plt.title(labels[train[26][1]])

def cross_validation(dataset):
  X, Y = list(), list()
  for x, y in dataset:
    X.append(x)
    Y.append(y)

  return X, Y

def normalize(X):
  return np.array(X)/255.0

def reshape(X, Y, fig_size):
    X = X.reshape(-1, fig_size[0], fig_size[1], 1)
    Y = np.array(Y)
    return X, Y

def data_arg(datagen=None):
    if datagen is None:
        return ImageDataGenerator(
            featurewise_center = False,
            samplewise_center = False,
            featurewise_std_normalization = False,
            samplewise_std_normalization = False,
            zca_whitening = False,
            rotation_range = 25
        )
    return datagen

X_train, y_train = cross_validation(train)
X_test, y_test = cross_validation(test)

X_train = normalize(X_train)
X_test = normalize(X_test)

X_train, y_train = reshape(X_train, y_train, (image_size, image_size))
X_test, y_test = reshape(X_test, y_test, (image_size, image_size))

datagenerator = data_arg(None)
datagenerator.fit(X_train)

model = models.Sequential()
model.add(keras.layers.Conv2D(32, (3,3),strides=1, padding='same', activation = 'relu', input_shape=(200,200,1)))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.MaxPooling2D((2,2), strides= 2, padding='same'))
model.add(keras.layers.Conv2D(32, (3,3),strides = 1, activation= 'relu', padding='same'))
model.add(keras.layers.Conv2D(32, (3,3),strides = 1, activation= 'relu', padding='same'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.MaxPooling2D((2,2), strides= 2, padding='same'))
model.add(keras.layers.Conv2D(64, (3,3),strides = 1, activation= 'relu', padding='same'))
model.add(keras.layers.Conv2D(64, (3,3),strides = 1, activation= 'relu', padding='same'))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.MaxPooling2D((2,2), strides=2, padding = 'same'))
model.add(keras.layers.Conv2D(128, (3,3),strides = 1, activation = 'relu'))
model.add(keras.layers.Conv2D(128, (3,3),strides = 1, activation = 'relu'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.MaxPooling2D((2,2), strides=2, padding = 'same'))
model.add(keras.layers.Conv2D(256, (3,3),strides = 1, activation = 'relu'))
model.add(keras.layers.Conv2D(256, (3,3),strides = 1, activation = 'relu'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.MaxPooling2D((2,2), strides=2, padding = 'same'))
model.add(keras.layers.Conv2D(512, (3,3),strides = 1, activation = 'relu'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.BatchNormalization())
model.add(keras.layers.MaxPooling2D((2,2), strides=2, padding = 'same'))
model.add(keras.layers.Flatten())
model.add(keras.layers.Dense(units = 128, activation= 'relu'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.Dense(3, activation = 'softmax'))

model.compile(optimizer= 'nadam', loss= 'sparse_categorical_crossentropy', metrics = ['accuracy'])

print(model.summary())

vis_utils.plot_model(model, to_file = 'model.png', show_shapes = True, show_layer_names = True)

run = model.fit(datagenerator.flow(X_train, y_train), epochs = 125, validation_data = (X_test, y_test))

loss_train = run.history['loss']
epochs = range(1,126)
plt.figure(figsize=(6,4), dpi=100)
plt.plot(epochs, loss_train, 'g', label = 'Train loss')
plt.title("Training Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

loss_val = run.history['val_loss']
epochs = range(1,126)
plt.figure(figsize=(6,4), dpi=100)
plt.plot(epochs, loss_val, 'g', label = 'Val loss')
plt.title("Testing Loss")
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

pred = model.predict(X_test)
pred_y = np.argmax(pred, axis=1)

print('Classification report')
print()
print(classification_report(y_test, pred_y, target_names=labels))

cmap = confusion_matrix(y_test, pred_y)
plt.figure(figsize = (4, 4), dpi = 150)
hm = sns.heatmap(data=cmap,
                annot=True,
                fmt='g')

accuracy  = accuracy_score(y_test, pred_y)
precision  = precision_score(y_test, pred_y, average='weighted')
recall  = recall_score(y_test, pred_y, average = 'weighted')
f1  = f1_score(y_test, pred_y, average= 'weighted')

print("Accuarcy Score----> ", accuracy)
print("Precision Score---> ", precision)
print("Recall Score-----> ", recall)
print("F1 Score-------> ", f1)